# -*- coding: utf-8 -*-
"""uk_hpi_Dec.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L0zJEw5D1ZUK5IdWqu1TKvyNuYdOhH5h

# UK House Price Index (UK HPI)
### Time Series Modelling (ARIMA, ARIMAX, ETS)

This notebook performs a full ready pipeline:
1. Load and clean the UK HPI dataset
2. Exploratory Data Analysis (EDA)
3. Build a monthly national-level time series of `AveragePrice`
4. Train/test split with log transform
5. Stationarity checks (ADF) and ACF/PACF
6. Model 1: ARIMA (benchmark)
7. Model 2: ARIMAX with exogenous variables
8. Model 3: ETS (Holt–Winters)
9. Model comparison using RMSE, MAE, MAPE
10. Saving models and results for reproducibility

## Imports
"""

import os
import warnings

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import statsmodels.api as sm
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from statsmodels.tsa.stattools import adfuller

from sklearn.metrics import mean_absolute_error, mean_squared_error

# Suppress non-critical warnings for a cleaner notebook
warnings.filterwarnings("ignore")

# Show all columns when displaying DataFrames
pd.set_option("display.max_columns", None)

# Output directory for saving plots, models, and metrics
OUTPUT_DIR = "results_dissertation"
os.makedirs(OUTPUT_DIR, exist_ok=True)

print("Setup complete. Output directory:", OUTPUT_DIR)

"""## Load UK HPI Dataset"""

# Path to the UK HPI full file (adjust if needed)
DATA_PATH = "UK-HPI-full-file-2025-07.csv"

# Load the CSV into a DataFrame
df = pd.read_csv(DATA_PATH)

print("Shape (rows, columns):", df.shape)
display(df.head())

# Print info to inspect data types and non-null counts
df.info()

from google.colab import drive
drive.mount('/content/drive')

"""## Type Conversion and Basic Cleaning"""

# Convert Date column to datetime
df["Date"] = pd.to_datetime(df["Date"], errors="coerce")

# Identify non-numeric columns
non_numeric = ["Date", "RegionName", "AreaCode"]
numeric_cols = [c for c in df.columns if c not in non_numeric]

# Convert all numeric columns to numeric types (coerce errors to NaN)
df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors="coerce")

print("Completed type conversions.")
print("Numeric columns:", len(numeric_cols))
display(df.head())

"""## Exploratory Data Analysis (EDA)

### Missing Values and Duplicates
"""

# Count missing values per column
missing = df.isna().sum().sort_values(ascending=False)
print("Missing values per column (top 20):")
print(missing.head(20))

# Count duplicate rows
dup_count = df.duplicated().sum()
print("\nTotal duplicate rows:", dup_count)

# Bar plot of missing values
plt.figure(figsize=(12, 6))
missing.plot(kind="bar")
plt.title("Missing Values per Column")
plt.ylabel("Count of Missing Values")
plt.xticks(rotation=90)
plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_DIR, "missing_values.png"), dpi=300)
plt.show()

"""### Summary Statistics for Numeric Variables"""

# Descriptive statistics for numeric columns
desc_stats = df.describe().T
display(desc_stats)

"""### Regional Average Prices (Top 10 Regions)"""

# Compute mean AveragePrice per RegionName
region_mean = (
    df.groupby("RegionName", dropna=False)["AveragePrice"]
    .mean()
    .sort_values(ascending=False)
)

top10 = region_mean.head(10)
print("Top 10 regions by average price:")
display(top10)

# Bar plot of top 10 regions
plt.figure(figsize=(10, 5))
sns.barplot(x=top10.index, y=top10.values)
plt.title("Top 10 Regions by Average House Price")
plt.ylabel("Average Price (£)")
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_DIR, "top10_regions.png"), dpi=300)
plt.show()

"""### UK-wide Average House Price Trend Over Time"""

# Aggregate AveragePrice by Date (UK-wide mean)
uk_trend = df.groupby("Date", dropna=False)["AveragePrice"].mean().reset_index()

plt.figure(figsize=(10, 5))
plt.plot(uk_trend["Date"], uk_trend["AveragePrice"])
plt.title("UK Average House Price Over Time")
plt.xlabel("Date")
plt.ylabel("Average Price (£)")
plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_DIR, "uk_trend.png"), dpi=300)
plt.show()

"""## Build Monthly National-Level Time Series"""

# Aggregate AveragePrice by Date into a monthly time series
df_monthly = df.groupby("Date")["AveragePrice"].mean().to_frame()

# Force a regular monthly-start frequency
df_monthly = df_monthly.asfreq("MS")

# Fill missing months by linear interpolation
df_monthly["AveragePrice"] = df_monthly["AveragePrice"].interpolate()

print("Monthly time series head:")
display(df_monthly.head())

# Plot the monthly UK-wide house price series
df_monthly.plot(figsize=(12, 5), title="UK Average House Price (Monthly)")
plt.ylabel("Average Price (£)")
plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_DIR, "uk_monthly_trend.png"), dpi=300)
plt.show()

"""## Train/Test Split and Log Transformation"""

# Log-transform AveragePrice to stabilise variance
y = np.log(df_monthly["AveragePrice"])
y = y.dropna()

# Choose test horizon (number of months held out)
test_horizon = 24  # last 24 months as test set

# Split into training and test sets
y_train = y.iloc[:-test_horizon]
y_test = y.iloc[-test_horizon:]

print("Train period:", y_train.index.min(), "to", y_train.index.max())
print("Test period :", y_test.index.min(), "to", y_test.index.max())
print("Training length:", len(y_train), "Test length:", len(y_test))

"""## Stationarity Check and ACF/PACF Analysis"""

# Augmented Dickey–Fuller test on the training series
adf_result = adfuller(y_train)
print("ADF Statistic:", adf_result[0])
print("p-value      :", adf_result[1])
print("Critical Values:")
for key, value in adf_result[4].items():
    print(f"    {key}: {value}")

# First difference of log prices (for ACF/PACF)
y_diff = y_train.diff().dropna()

# Plot ACF and PACF for the differenced series
fig, ax = plt.subplots(1, 2, figsize=(12, 4))
plot_acf(y_diff, ax=ax[0], lags=20)
plot_pacf(y_diff, ax=ax[1], lags=20, method="ywm")
ax[0].set_title("ACF of 1st Difference")
ax[1].set_title("PACF of 1st Difference")
plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_DIR, "acf_pacf.png"), dpi=300)
plt.show()

"""## Helper Function: Forecast Accuracy Metrics"""

def evaluate_forecast(y_true, y_pred, model_name="model"):
    """
    Compute RMSE, MAE, and MAPE between true and predicted values.
    Both y_true and y_pred should be on the original (non-log) scale.
    """
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100

    print(f"{model_name} – RMSE: {rmse:,.2f} | MAE: {mae:,.2f} | MAPE: {mape:,.2f}%")
    return rmse, mae, mape

"""## Model 1 - ARIMA"""

# Chosen order based on ACF/PACF and prior experimentation
arima_order = (1, 1, 1)
seasonal_order = (0, 1, 1, 12)

# Fit ARIMA model on the training data (log scale)
arima_model = ARIMA(
    y_train,
    order=arima_order,
    seasonal_order=seasonal_order
)
arima_results = arima_model.fit()
print(arima_results.summary())

# Diagnostic plots for ARIMA residuals
arima_results.plot_diagnostics(figsize=(12, 6))
plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_DIR, "arima_diagnostics.png"), dpi=300)
plt.show()

# ----------------------------------------------------------
# ARIMA Forecast for Test Period
# ----------------------------------------------------------

# Forecast 24 steps ahead (on log scale)
arima_forecast_log = arima_results.get_forecast(steps=test_horizon)
arima_mean_log = arima_forecast_log.predicted_mean
arima_conf_int_log = arima_forecast_log.conf_int()

# Convert log forecasts back to original (£) scale
arima_pred = np.exp(arima_mean_log)
arima_lower = np.exp(arima_conf_int_log.iloc[:, 0])
arima_upper = np.exp(arima_conf_int_log.iloc[:, 1])

# Actual test values on original scale
y_test_lin = np.exp(y_test)

# Evaluate ARIMA forecast
arima_rmse, arima_mae, arima_mape = evaluate_forecast(
    y_test_lin, arima_pred, model_name="ARIMA"
)

# Plot ARIMA predictions vs actuals
plt.figure(figsize=(12, 5))
plt.plot(np.exp(y_train), label="Train")
plt.plot(y_test_lin, label="Test (Actual)", color="black")
plt.plot(arima_pred.index, arima_pred, label="ARIMA Forecast", color="green")
plt.fill_between(arima_pred.index, arima_lower, arima_upper,
                 color="lightgreen", alpha=0.3, label="95% CI")
plt.title("ARIMA Forecast vs Actual (Test Period)")
plt.xlabel("Date")
plt.ylabel("Average Price (£)")
plt.legend()
plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_DIR, "arima_forecast_test.png"), dpi=300)
plt.show()

"""## Construct Exogenous Variables for ARIMAX"""

# ----------------------------------------------------------
# Exogenous Variables for ARIMAX
# ----------------------------------------------------------

# Set Date as index and ensure sorted order
df_sorted = df.set_index("Date").sort_index()

# Choose economically meaningful exogenous variables
exog_cols = ["DetachedPrice", "SemiDetachedPrice", "TerracedPrice", "SalesVolume"]

# Aggregate by date (mean) and ensure monthly frequency
X = df_sorted[exog_cols].groupby(df_sorted.index).mean().asfreq("MS")

# Fill missing values by forward/backward fill
X = X.fillna(method="ffill").fillna(method="bfill")

# Align X to the same index as the target series y
X = X.reindex(y.index)
X = X.fillna(method="ffill").fillna(method="bfill")

# Train/test split for exogenous variables
X_train = X.iloc[:-test_horizon]
X_test = X.iloc[-test_horizon:]

print("Exogenous variables (train) shape:", X_train.shape)
print("Exogenous variables (test) shape :", X_test.shape)
display(X.head())

"""## 10. Model 2 – ARIMAX"""

# Use the same ARIMA orders as the benchmark model
arimax_model = SARIMAX(
    endog=y_train,
    exog=X_train,
    order=arima_order,
    seasonal_order=seasonal_order,
    enforce_stationarity=False,
    enforce_invertibility=False
)

arimax_results = arimax_model.fit()
print(arimax_results.summary())

# Diagnostic plots for ARIMAX residuals
arimax_results.plot_diagnostics(figsize=(12, 6))
plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_DIR, "arimax_diagnostics.png"), dpi=300)
plt.show()

# ----------------------------------------------------------
# ARIMAX Forecast for Test Period
# ----------------------------------------------------------

# Forecast using exogenous variables for the test horizon
arimax_forecast_log = arimax_results.get_forecast(steps=test_horizon, exog=X_test)
arimax_mean_log = arimax_forecast_log.predicted_mean
arimax_conf_int_log = arimax_forecast_log.conf_int()

# Convert back to original (£) scale
arimax_pred = np.exp(arimax_mean_log)
arimax_lower = np.exp(arimax_conf_int_log.iloc[:, 0])
arimax_upper = np.exp(arimax_conf_int_log.iloc[:, 1])

# Evaluate ARIMAX forecast against actual test values
arimax_rmse, arimax_mae, arimax_mape = evaluate_forecast(
    y_test_lin, arimax_pred, model_name="ARIMAX"
)

# Plot ARIMAX predictions vs actuals
plt.figure(figsize=(12, 5))
plt.plot(np.exp(y_train), label="Train")
plt.plot(y_test_lin, label="Test (Actual)", color="black")
plt.plot(arimax_pred.index, arimax_pred, label="ARIMAX Forecast", color="green")
plt.fill_between(arimax_pred.index, arimax_lower, arimax_upper,
                 color="lightgreen", alpha=0.3, label="95% CI")
plt.title("ARIMAX Forecast vs Actual (Test Period)")
plt.xlabel("Date")
plt.ylabel("Average Price (£)")
plt.legend()
plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_DIR, "arimax_forecast_test.png"), dpi=300)
plt.show()

"""## 11. Model 3 – ETS (Holt–Winters)"""

# Use the same log-transformed series and train/test split
y_log = y.copy()
y_train_ets = y_log.iloc[:-test_horizon]
y_test_ets  = y_log.iloc[-test_horizon:]

# -------------------------------
# Fit ETS model (log scale)
# -------------------------------
ets_model = ExponentialSmoothing(
    y_train_ets,
    trend="add",
    seasonal="add",
    seasonal_periods=12,
    initialization_method="estimated"
).fit(optimized=True)

print("ETS model fitted.")

# -------------------------------
# Point forecast (log -> £)
# -------------------------------
ets_forecast_log = ets_model.forecast(steps=test_horizon)
ets_pred = np.exp(ets_forecast_log)

# -------------------------------
# 95% Prediction Interval (simulation)
# -------------------------------
# We simulate many possible future paths from the fitted ETS model,
# then take the 2.5% and 97.5% quantiles at each horizon step.
n_sims = 2000  # increase for smoother intervals (e.g., 5000) if you want
sim_log = ets_model.simulate(
    nsimulations=test_horizon,
    repetitions=n_sims,
    anchor="end"          # start simulating from end of training
)

# sim_log is (steps x repetitions). Convert to DataFrame for easy quantiles
sim_log_df = pd.DataFrame(sim_log, index=ets_forecast_log.index)

# Quantiles in log space
ets_lower_log = sim_log_df.quantile(0.025, axis=1)
ets_upper_log = sim_log_df.quantile(0.975, axis=1)

# Convert interval bounds back to £
ets_lower = np.exp(ets_lower_log)
ets_upper = np.exp(ets_upper_log)

# Actual test values on £ scale
y_test_ets_lin = np.exp(y_test_ets)

# -------------------------------
# Evaluate ETS forecast
# -------------------------------
ets_rmse, ets_mae, ets_mape = evaluate_forecast(
    y_test_ets_lin, ets_pred, model_name="ETS (Holt-Winters)"
)

# -------------------------------
# Plot ETS predictions vs actuals + 95% CI
# -------------------------------
plt.figure(figsize=(12, 5))
plt.plot(np.exp(y_train_ets), label="Train")
plt.plot(y_test_ets_lin, label="Test (Actual)", color="black")
plt.plot(ets_pred.index, ets_pred, label="ETS Forecast", color="green")

plt.fill_between(
    ets_pred.index,
    ets_lower,
    ets_upper,
    color="lightgreen",
    alpha=0.3,
    label="95% CI"
)

plt.title("ETS (Holt–Winters) Forecast vs Actual (Test Period) with 95% CI")
plt.xlabel("Date")
plt.ylabel("Average Price (£)")
plt.legend()
plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_DIR, "ets_forecast_test_with_ci.png"), dpi=300)
plt.show()

"""## 12. Model Comparison (ARIMA vs ARIMAX vs ETS)"""

# Construct a DataFrame summarising the accuracy metrics
comparison = pd.DataFrame({
    "Model": ["ARIMA", "ARIMAX", "ETS (Holt-Winters)"],
    "RMSE": [arima_rmse, arimax_rmse, ets_rmse],
    "MAE": [arima_mae, arimax_mae, ets_mae],
    "MAPE (%)": [arima_mape, arimax_mape, ets_mape],
})

print("Model Comparison on 24-month Test Period:")
display(comparison)

# Save comparison table to CSV
comparison.to_csv(os.path.join(OUTPUT_DIR, "model_comparison_metrics.csv"), index=False)

"""## 13. Save Fitted Models for Reproducibility"""

# Save fitted models to disk for future reuse
arima_results.save(os.path.join(OUTPUT_DIR, "ARIMA_model.pkl"))
arimax_results.save(os.path.join(OUTPUT_DIR, "ARIMAX_model.pkl"))
ets_model.save(os.path.join(OUTPUT_DIR, "ETS_model.pkl"))

print("All models saved successfully in:", OUTPUT_DIR)